# 设计文档



## 一、参考编译器介绍

实验主要参考了 Hyggge 学长的编译器：[Petrichor](https://github.com/Hyggge/Petrichor)、和毕昇杯“喵喵队仰卧起坐”队编译器：[compiler2022-meowcompiler](https://gitlab.eduxiji.net/educg-group-12619-928705/compiler2022-meowcompiler)。

文件结构的设计主要学习了 Hyggge 学长，分成了前中后端。不一样的是我把中间代码的先关类和优化都归与中端，前端主要负责词法分析，语法分析和错误处理。

在生成中间代码 LLVM 时，由于笔者愚钝，并不了解 "万物皆`Value`" 这一思想的核心，也不清楚分成 `User`设计的原因。看完 Hyggge 学长的编译器设计恍然大悟，不由发觉 LLVM 设计的精妙之处，后续编写代码是更是享受了这种结构带来的极大便利。

compiler2022-meowcompiler 在文件分类上更加详细，包括前中后端、中间代码、错误处理等都分成多个包。因鉴于理论课上学习到编译器结构，故没有作这种详细的区分。但是在优化上，毕昇杯“喵喵队仰卧起坐”队编译器做了非常多的优化，令人叹服，给我的优化带来很多启发。

<br>

## 二、编译器总体设计

### 2.1 文件组织

文件组织如下：

```
├─docs                          # 文档
├─src
│  ├─backend                    # 后端代码
│  │  └─mips                    # 生成 mips 相关代码
│  │
│  ├─frontend                   # 前端代码
│  │  ├─lexer                   # 词法分析器
│  │  ├─semantics               # 语义分析器
│  │  │  └─symbol               # 符号表
│  │  └─syntax                  # 语法分析器
│  │      └─ast                 # 语法树
│  │
│  ├─midend                     # 中端代码
│  │  ├─llvmir                  # llvm-ir 定义
│  │  │  ├─type
│  │  │  └─value
│  │  └─optimize                # 中端优化类
│  │
│  └─util                       # 工具类
└─test                          # 测试样例集
```



### 2.2 总体结构

笔者的编译器采用Java语言编写，实现从 C 语言子集到 MIPS 的编译。在结构上，按功能和特点分为前端，中端，后端三部分：

- 前端：主要包括和输入源文件（C代码）有关的分析处理，有词法分析、语法分析、语义分析，错误处理。
- 中端：包括中间代码的相关部分，有 LLVM IR 的定义，以及常见的中间代码优化。
- 后端：包括和目标指令（MIPS）有关的代码，如 MIPS 指令类的定义，`MipsBuilder` 单例辅助生成 MIPS等等。



### 2.3 接口设计

如下展示编译器几个重要过程中的`public`方法：

**词法分析**：

- `next()`用于语法分析程序调用，解析并获取 下一个单词。
- `foresee(int times)`向前偷看单词。

**语法分析**：

- `parseCompUnit()`递归下降解析程序，作语法分析。通过调用词法分析器的接口，生成语法树。

**语义分析、生成中间代码**：

- `checkError()`对语法树作错误分析，包括词法错误、语法错误、语义错误。
- `genIR()`将语法树转成 LLVM 中间代码形式。

**目标代码生成**：

- `genMips()`将 LLVM 转换成对应的 MIPS 汇编。

**代码优化**：

- `SSA.transToSSA(Function f, CFG c)`将 LLVM 的 `Function`转成 SSA 形式。
- `SSA.eliminatePhi(Function f, CFG c)`消除 `Function` 的 `phi` 指令。
- `GVN.simplify(Function f, CFG c)`GVN优化。
- `DeadCodeRemover.deleteDeadInstr(Function f)`死代码删除。

<br>

## 三、词法分析设计

### 3.1 编码前设计

词法分析部分通过对输入的程序源码字符串进行从左往右的解析，分析出有独立词法含义的符号进行存储，并识别出其类别以供语法分析器进行使用。

词法分析的规则见下图：

<img src=".\images\lexer-1.png" style="zoom: 67%;" />

为了提高编译器的执行效率，设计时我选择使用语法分析和词法分析统一的方式，即词法分析和语法分析都在同一遍中实现。

词法分析部分主要涉及的类有`Lexer`和`LexType`。

`LexType`枚举类，存放每种单词的类别，对应上表规则中的类别码，便于后续的语法分析使用。其内部的逻辑功能比较简单，只需实现根据对应单词 `token` 解析类别码的功能即可。

```java
public static LexType parse(String token) {
    switch (token) {
        case "main":
            return MAINTK;
        //...
    }
}
```

在 `LexType`中实现`parse`函数的原因是为词法分析器提供接口，完成两个类的解耦，简化代码的同时，也避免因为在 `Lexer` 中写错单词带来的隐蔽 bug，方便调试。

`Lexer`词法分析器，存放词法分析每次得到的结果，包括`token`、`lexType` 等，内部封装了词法分析的主要逻辑。

```java
public class Lexer {
    private final String source;        // input program
    private String token;               // value of word
    private LexType lexType;            // type of word
    private int lineNumber;             // number of line
    private int curPos;                 // index
    //...
}
```

`Lexer`词法分析的核心逻辑放在`next`函数中，该函数读取下一个单词，并更新到对应属性上，提供接口是的语法分析器可以进行查看。

`next`读取单词的逻辑根据单词类别有所区别：

- 分界符：`!`、`&&`、`||`、`+`、`-`、`*`、`/`、`%`、`<`、`<=`、`>=`、`==`、`>`、`!=`、`=`、`;`、`,`、`(`、`)`、`[`、`]`、`{`、`}`。这类单词的识别直接特殊处理，根据自动机判断即可。但对于双分界符需要多判断下一个字符。比如`>=`，读取到`>`是需要再判断下一个字符是不是`=`，是则识别出`>=`，否则识别出`>`。

- 无符号整数：识别时如果发现**刚开始**读到的字符是一个数字，则循环读取数字拼接。（标识符中要求以字母开头，因此不会和无符号整数的识别相矛盾）

- 注释：分成单行注释和多行注释，需要与除号的识别合并处理，是词法分析的难点。下面给出实现的总体思路（省去了繁琐的实现细节）。

  ```java
  if (source.charAt(curPos) == '/') {
      token = "/";
      if (curPos + 1 < source.length() && source.charAt(curPos + 1) == '/') {
          // 不断读取下个字符直至遇到换行符或结尾
          return next(); 
      } else if (curPos + 1 < source.length() && source.charAt(curPos + 1) == '*') {
          curPos += 2;
          while (curPos < source.length()) {
              // 不断读取字符知道遇到 *
              // 不断读取 *
              // 判断：如果是 /,在此调用 next()，否则继续循环
          }
      }
      lexType = LexType.parse(token);
  }
  ```

- 标识符：程序中的变量。如果不是上述的字符类型，直接不断读取下一个字符直至到空白字符。

- 保留字：`mian`、`const`、`int`、`break`、`continue`、`if`、`else`、`for`、`getint`、`printf`、`return`、`void`。保留字的识别和标识符的识别可以放在一起进行，通过`LexType`的`parse`方法可以判断是保留字还是标识符，从而简化代码。

  

### 3.2 编码后修改

在实现语法分析过程中，发现不可避免地需要使用**预读**操作，因为先前设计的词法分析器中没有实现这个功能，所以添加了`foresee`方法用于返回预读的结果。因为语法分析通过预读操作判定下一步解析动作只涉及了单词类别码，因此返回值是`ArrayList<LexType>`。

在`foresee`函数逻辑中，保存当前的环境(`token`、`lexType`、`lineNumber`、`curPos`)，然后调用已经实现好的`next`函数得到预读结果，在返回时恢复保存的环境。

```java
public ArrayList<LexType> foresee(int times) {
    // 保存现场
    ArrayList<LexType> res = new ArrayList<>();
    for (int i = 0; i < times; ++i) {
        this.next();
        res.add(this.lexType);
    }
    // 恢复现场
    return res;
}
```

<br>

## 四、语法分析设计

### 4.1 编码前设计

语法分析阶段需要利用词法分析器提取单词，根据文法规则自顶向下，通过递归下降分析法，构建出一棵语法树。

语法分析部分需要完成的类有`Parser`、`SyntaxType`、以及各种结点类。在设计阶段，为了可以将程序转化成严谨完整的语法树，我为每一个语法结构都创建了一个类，这些类都继承于`Node`结点类。比如下面的语法规则，就需要为`Block`、`Decl`、`Stmt`分别建类。（语法分析不需要输出"BlockItem"，在文法中是一个多余的非终结符，因此没有建类）

<img src="images\parser-1.png" style="zoom:70%;" />

`SyntaxType`枚举类，作用和`LexType`几乎一样，标识每一个语法树结点的类别。这部分逻辑和`LexType`很像，但因为文法规则每个非终结符我都建立了类，为了做区别，`SyntaxType`需要增加更多的语法类别作区分。之所以把这两个类分开写，是因为词法分析的词法类别和文法分析的语法类别我认为是两个部分的内容，应该有所区分，虽然代码和逻辑是重复的，但我认为这么做可以使代码结构和类的功能有清晰的划分。

语法树的结点类，这部分所有类都继承自公共基类`Node`。在语法分析部分，这些类的功能几乎都是一致的，只需要存储子节点即可，因此这些公共逻辑都写在了`Node`中。

```java
public class Node {
    protected SyntaxType type;              // type of syntax
    protected ArrayList<Node> children;     // children nodes
}
```

虽然在语法分析阶段，为每一个语法成分都写一个类劳心伤神，但这是必要的，因为每个类的语法逻辑是有区别的，在后续生成中间代码可以在每个子类中单独写，避免做过多的特判，也避免用一个类表示所有节点导致类的体积过于臃肿。

`Parser`语法分析器，封装了语法分析的所有逻辑，采用递归下降分析方法，为每一个语法结构也就是文法中的非终结符，都实现一个`parseXXX`方法，返回该非终结符对应的对象。一旦要识别要匹配某一非终结符时，则调用其方法即可。

通过分析文法规则，需要处理两类问题，分别是**多产生式**和**左递归问题**。

多产生式在该编译实验中以下面两条文法规则为代表：

<img src="images\parser-2.png" style="zoom:67%;" />

<img src="images\parser-3.png" style="zoom:67%;" />

对于第一条文法，我采用预读单词的办法，在词法分析器`Lexer`中实现预读的接口。对于第一条文法而言，发现无论什么情况下总能通过预读三个单词就可以判断调用那个非终结符的`parse`方法。

而对于第二条文法中有`Stmt-> Lval = Exp; | [Exp]; | LVal = getint();`这三个产生式是本次实验的难点。和上一条文法不同，`Exp` 可以经过若干有限次推导得到 `Lval`，同时也无法预判 `Lval` 的长度，因此预读的方法不可行。所以我采用对于这三种产生式的情况都用 `Exp` 的解析方法去解析，如果解析后下一个字符是 `;` ，那么刚才的解析方法就是正确的，如果下一个字符是 `=`，那么就可以说明前面的符号应该是 `Lval`，在从`Exp` 的树中截取 `Lval` 的子树当作上次解析的结果。

第二个难点问题是左递归问题。因为编译器解析程序的顺序是从左往右进行的，如果遇到做递归文法不作修改，那么`parseXXX`方法会进入无穷的调用，从而出错。因此左递归文法需要经过变形可以变成正则表达式，但是如果变化后，原先的语法树也会跟着变形。为了保证语法树不变，每次读到分界符时，对之前解析得到的树结点重新进行生成，保证语法树不变。

以文法 `AddExp → MulExp | AddExp ('+' | '−') MulExp`为例进行说明：

```java
private AddExp parseAddExp() {
    MulExp mulExp = parseMulExp()
    AddExp addExp = new AddExp(mulExp);
    while (true) {
        if (读到了 + 或 -) {
        	addExp = new AddExp(addExp, parseMulExp());
        }
    }
    return addExp;
}
```

解决完上述问题，语法分析器就大抵都可以实现了。



### 4.2 编码后修改

在错误处理部分，发现语法分析预留的错误处理接口不太适用。因为笔者设计的错误分析是重新的一遍，即在语法分析生成的抽象语法树上进行的，因此语义错误，语法错误等信息都必须携带到语法树上。这要求语法分析需要能够容忍一定的语法错误，如右括号缺省，分号缺失等等。而在之前语法分析过程中，往往需要这些终结符号作为分界辅助分析。如今要能够处理这些缺失的情况，需要对语法分析的逻辑做些调整。往往还要根据文法计算 FIRST 集 FOLLOW 集等。

<br>

## 五、错误处理设计

### 5.1 编码前设计

编译器的错误处理是比较复杂的，因为并不知道输入的源程序串会出现怎么样的错误，这会导致词法分析乃至语法分析都难以实现。因此本实验的错误处理是限定在一约束要求内的，需要考虑的错误如下表所示。

![](images\error-1.png)

这些错误大抵可以分成三类：

- 词法分析错误：a
- 语法分析错误：i，j，k
- 语义分析错误：b，c，d，e，f，g，h，l，m

在设计错误处理时，为了避免语法分析器代码量过于庞大，导致后续难以维护，添加了新的语义分析类`SemanticAnalyzer`，在语义分析中完成错误分析和中间代码生成，当然这样需要对语法分析得到的语法树进行操作，相当于扫描了程序两遍，即便会有效率的损失，但为了便于代码的可拓展性和可维护性来说是值得的。

具体来说，每个语法成分都继承自基类 `Node`，并重写`checkError`方法，执行对应的错误处理逻辑。

```java
public String checkError() {
    StringBuilder sb = new StringBuilder();
    ...// 当前语法成分涉及的错误检查
    
    for(Node child: children) {   // 递归检查子节点语法成分
        sb.append(child.checkError());
    }
    return sb.toString();
}
```

词法逻辑的错误需要对词法分析`Lexer`稍作修改，然后在结点中判断字符串中是否有对应非法符号。

语法错误的处理即判断指定子节点是否符合文法要求，比如判断是否缺少右括号。当然这需要对语法分析作调整，允许语法分析可以处理简单语法错误的情况，保证语法树的正常生成。这一部分难点在于语法分析的修改，需要进行比较多的特判。

语义错误的处理就必须依赖于符号表。在我的设计中，符号表单独定义为一个类，并用`HashMap`数据结构存储识别的符号，能够加快符号的查找。符号则分成两类：函数和变量，也需要分别建类并集成于基类`Symbol`。上述 `checkError` 方法的参数就是符号表，表示当前对该语法成分进行检查时，当前最内层的符号表。符号表之间是连的，可以形成一颗树，**子符号表仅在进入函数、进入块内会被创建，在退出函数和块时会回溯到父结点符号表**。子符号表可以查找父符号表定义的符号。比如进行变量重定义判断时，只查找当前层的符号表；在检查符号是否定义时，则要从内到外查找符号是否存在，如果没有则记录名字未定义错误。

大部分的语义错误在符号表的支持下都可以完成，这部分比较繁琐，要根据文法一步步进行检查，不能遗漏。但是有两类语义错误需要关注。一类是`return`语句错误和`break`、`continue`错误。这一类错误需要知道语法成分处于什么符号表内。`return`语句需要能够查找所在符号表对应函数的返回值类型，`break`，`continue`需要知道是否处于循环块内。因此这类错误要求对不同类型的符号表作区分，因此我为符号表类增加了名字、类别的属性以便查询。

```java
public class SymbolTable {
    public enum TableType {
        GLOBAL, MAIN_FUNC, FUNC, BLOCK, IF_BLOCK, FOR_BLOCK
    }
    private final TableType type;
    private final SymbolTable prev;
    private final ArrayList<SymbolTable> nexts;
    private final LinkedHashMap<String, Symbol> symbols;
    private final String funcName;   // FUNC、MAIN_FUNC 特有属性
}
```

第二类错误是处理函数类型匹配的问题。类型匹配需要判断参数的维数是否符合定义。处理维数时不能仅看符号在符号表中的定义，还要根据使用细分。比如一个二维变量`a`，`a[..][..]`就是一个 int 变量，`a[..]`则是一个一维数组。此外还会出现以函数返回值为参数的情况，比如`func1(func2(a))`，这时候需要识别出`func2(a)`才是`func1()`的参数，而不是`a`。这一过程可以变成一递归过程，因此需要根据文法作细致的处理。所幸实验在类型匹配上要求并不是非常严苛，不需要依据参数维数的值做检查，也不检查函数返回值为空，所以实现起来虽然麻烦，但并不算困难。

最后，在语义分析器类中，调用语法树最顶层的节点的`checkError`方法，完成错误分析。



### 5.2 编码后修改

错误处理中我的符号表是串起来的，但并没有统一管理。在代码生成时发现符号表必须重新创建，填表等操作需要重复编写，因此我设计了一个`SymbolManager`类，并采用单例模式，管理当前程序所在的符号表，并提供查表填表等一系列接口，方便维护，也更容易使用。

以下展示了这个单例类中重要的接口

```java
package frontend.semantics.symbol;

import java.util.ArrayList;

public class SymbolManager {
    private final static SymbolManager instance = new SymbolManager();
    private SymbolTable curTable;	 // 当前所处的符号表
    private int depth;  			// 符号表数深度

    public static SymbolManager instance() {
        return instance;
    }

    // 创建新的符号表添加到当前符号表中
    public void createTable(SymbolTable.TableType type){...}

    // 回到父结点符号表
    public void tracebackTable() {...}
    
    // 查找变量符号
    public VarSymbol getVarSymbol(String name, boolean isAll) {...}
    
    // 查找函数符号
    public FuncSymbol getFuncSymbol(String name) {...}

    // 新增变量符号
    public VarSymbol addVarSymbol(boolean isConst, String name, ArrayList<Integer> dimensions, ArrayList<Integer> initials) {...}
    
    // 新增函数符号
    public FuncSymbol addFuncSymbol(String name, String type) {...}

    // 函数参数回填
    public void addFuncParam(ArrayList<Integer> lens) {...}
}

```

对于`checkError`方法不需要接受任何参数，只需要在方法里调用上述实例类的接口维护符号表即可。

<br>

## 六、代码生成设计

### 6.1 编码前设计

#### 6.1.1 中间代码生成

笔者选择 LLVM 作为中间代码，一是使用 LLVM 优秀的指令设计，可以避免自己设计四元式出现难以处理的bug，二是教程对于 LLVM 的生成和优化都比较详细，做起来更简单。

生成中间代码是在语法树上完成的，因此和错误处理类似，在语法成分的结点上实现`genIR`方法，然后处理各自的生成逻辑，自上而下递归进行。并且需要重新建立和维护符号表。因此生成中间代码可以和错误处理同时进行，不过这样虽然程序变得高效，但是两个过程耦合度高，不好维护，因此笔者仍然采用分离实现的办法。

LLVM 核心观点是 "一切皆 Value"。本着这个思想， 我的设计中设计了 `Value` 这个基类。此外，LLVM 中有还有`User`，表示使用其他`Value`的`Value`，最常见的就是指令。如下是我的 LLVM 相关设计：

<img src=".\images\llvm-value.png" style="zoom:80%;" />

整个 LLVM 的框架是可以理解为：

```
└─ Module
   ├─ GlobalStr         
   ├─ GlobalVar                    
   ├─ Function                    
   │  ├─ Param                  
   │  └─ BasicBlock
   │      └─Instr
   ...
```

为了区别不同的`Value`，我设计了`ValueType`类，并且设计`VarType`、`ArrayType`、`PointerType`继承自`ValueType`，以便 LLVM 中间代码区分类型。此外，考虑到所有的全局变量都有初始值，而且对于数组而言，其初值是一个递归的过程，比如下面的例子：

```c
int a[3][2] = {{1,2},{3,4},{5,6}};

@global_0 = dso_local global [3 x [2 x i32]] [[2 x i32] [i32 1, i32 2], [2 x i32] [i32 3, i32 4], [2 x i32] [i32 5, i32 6]]
```

因此这个递归过程在我的设计里是放到`ValueType`中的，但因为不是所有的类型都会有初值，所以我设计了`Initializable`接口，`VarType` 和 `ArrayType` 实现之。

```java
public class VarType extends ValueType implements Initializable {
    private final int width;
    private final int initial;
    
    @Override
    public ArrayList<Integer> getInitials() {
        ArrayList<Integer> ret = new ArrayList<>();
        ret.add(initial);
        return ret;
    }
}
```

`width`主要用去区分`i32`还是`i1`。`initial`就是一个`int`变量的初值，但不是所有`VarType`都有这个属性值，仅针对于全局变量。

```java
public class ArrayType extends PointerType implements Initializable {
    private int cnt;
    private final ValueType eleType;
    private final ArrayList<Initializable> initials;  // 全局int变量数组初始化
    private final boolean zeroInitializer;
    
    @Override
    public ArrayList<Integer> getInitials() {
        ArrayList<Integer> ret = new ArrayList<>();
        if (zeroInitializer) {
            for (int i = 0; i < size(); ++i) {
                ret.add(0);
            }
        } else {
            for (Initializable init : initials) {
                ret.addAll(init.getInitials());
            }
        }
        return ret;
    }
}
```

我设计了 `IRBuider` 单例类，其管理 LLVM 指令名字的分配，以及当前的 `Function`、`BasicBlcok`等，并为所有类型的 LLVM 中间代码设计了生成接口，对应语法树结点只需要合理调用这些接口就可以正确生成 LLVM 框架。

此外对于流程控制语句，因为需要实现短路求值，所以后续的基本块需要提前生成，但不填入`Function`中，把这些作为上下文信息存入`IRBuider`，根据这些上下文生成跳转指令。同时按照短路求值的特点，调整上下文的信息，改变跳转的目标块。以`LOrExp`为例：

```java
// LOrExp → LAndExp | LOrExp '||' LAndExp
public Value genIR() {
    BasicBlock trueBlock = IRBuilder.getInstance().getTrueBlock();
    BasicBlock falseBlock = (IRBuilder.getInstance().getFalseBlock() != null) ?
            IRBuilder.getInstance().getFalseBlock() : IRBuilder.getInstance().getLeaveBlock();
    
    Value value;
    if (children.size() > 1) {
        BasicBlock block = IRBuilder.getInstance().newBasicBlock();
        IRBuilder.getInstance().setFalseBlock(block);  // 新的false block

        value = children.get(0).genIR();  // 递归解析 LAndExp
        BrInstr brInstr = IRBuilder.getInstance().newBRInstr(value, trueBlock, block);
        IRBuilder.getInstance().addInstr(brInstr);

        IRBuilder.getInstance().addBasicBlock(block);
    }
    
    IRBuilder.getInstance().setFalseBlock(falseBlock);
    value = children.get(children.size() - 1).genIR();
    return value;
}
```



#### 6.1.2 目标代码生成

生成 MIPS 比语法树转 LLVM 相对容易得多，因为 LLVM 本身已经非常接近于 MIPS 了。因此生成 MIPS 几乎可以为每一种 `Value` 设计一个`genMips`方法，但因为生成 MIPS 应该属于后端的内容，如果把所有生成逻辑都写在对应 `Value` 的方法里，耦合性太强，故笔者参照中间代码，设计了一个 `MipsBuilder` 单例类，其中存放入寄存器分配，栈内存分配，栈指针等信息，并为每一种 LLVM 指令编写了对应的转化逻辑，每个 `Value` 的 `genMips `方法，仅需依照接口设计调用 `MipsBuider` 的对应方法即可。

```java
public class MipsBuilder {
    private static MipsBuilder instance = new MipsBuilder();
    private MipsProcedure procedure;   					// mips 汇编程序
    private LinkedHashMap<Value, Reg> valueRegMap;        // value -- reg
    private LinkedHashMap<Value, Integer> valueStackMap;  // value -- stack
    private int stackOffset;  							// 当前栈偏移($sp)
}
```

因为 LLVM 转 MIPS 几乎是一对一翻译，在没有考虑优化的情况下只需按照指令语义选择对应的 MIPS 指令等价转换即可。当然转成 MIPS 依赖于寄存器的管理，栈内存的分配。接下来介绍不考虑优化下我的存储管理策略。

现阶段的存储管理设计可谓是非常粗暴简单：所有的内存分配，除了全局变量是放在`.data`段以外，其他变量都是放在栈上的(`sp`)。因为没有考虑优化，所以在进入函数前，我就对每一个基本块，每一条指令分配好寄存器，且为一次性分配，当寄存器不够使，就把指令存储到栈上，记录其相对于`$sp`的偏移量，这就需要两个 `HashMap` 管理了。而每当进入一个函数是`$sp`寄存器都指向空闲的内存空间，在函数体内部，`$sp`不会作任何加减，当前仅当是函数调用指令时，`$sp`才会加上当前使用的栈的偏移，结束后再减回来。

可见在没有代码优化时我的存储管理是很简陋，这一点在引入寄存器分配优化后就会有所改善。

最后，需要再多提的一点是，`icmp`的翻译稍微和其他指令不同，如果依然按照一对一进行翻译的，可能会产生许多指令，但当将其与其`User`一并翻译时，就能有效合并指令。（`icmp`的`User`只能是`zext`或`br`）。

下面以 `br` 指令为例说明，其中 `cond` 由 `icmp` 的比较类型转换而来，`operand1`、`operand2` 是 `icmp` 指令的操作数。

```java
    public void brInstrToCmd(String cond, Value operand1, Value operand2, String tureName, String falseName) {
        LabelCmd trueLabel = getLabelCmd(tureName);
        LabelCmd falseLabel = getLabelCmd(falseName);
        Reg operandReg1 = takeRegOfValue(operand1, Reg.$t8, true);
        Reg operandReg2 = takeRegOfValue(operand2, Reg.$t9, true);
        switch (cond) {
            case "==":
                procedure.addTextCmd(new BranchCmd(BranchCmd.BranchCmdOp.beq, operandReg1, operandReg2, trueLabel));
                break;
            case "!=":
                procedure.addTextCmd(new BranchCmd(BranchCmd.BranchCmdOp.bne, operandReg1, operandReg2, trueLabel));
                break;
            case ">=":
                procedure.addTextCmd(new AluCmd(AluCmd.AluCmdOp.slt, Reg.$v1, operandReg1, operandReg2));
                procedure.addTextCmd(new BranchCmd(BranchCmd.BranchCmdOp.beq, Reg.$v1, Reg.$zero, trueLabel));
                break;
            case "<=":
                procedure.addTextCmd(new AluCmd(AluCmd.AluCmdOp.slt, Reg.$v1, operandReg2, operandReg1));
                procedure.addTextCmd(new BranchCmd(BranchCmd.BranchCmdOp.beq, Reg.$v1, Reg.$zero, trueLabel));
                break;
            case ">":
                procedure.addTextCmd(new AluCmd(AluCmd.AluCmdOp.slt, Reg.$v1, operandReg2, operandReg1));
                procedure.addTextCmd(new BranchCmd(BranchCmd.BranchCmdOp.bne, Reg.$v1, Reg.$zero, trueLabel));
                break;
            case "<":
                procedure.addTextCmd(new AluCmd(AluCmd.AluCmdOp.slt, Reg.$v1, operandReg1, operandReg2));
                procedure.addTextCmd(new BranchCmd(BranchCmd.BranchCmdOp.bne, Reg.$v1, Reg.$zero, trueLabel));
                break;
            default:
                break;
        }
        procedure.addTextCmd(new JumpCmd(JumpCmd.JumpCmdOp.j, falseLabel));
    }
```



### 6.2 编码后修改

代码生成中考虑的是程序的正确性，因此在做代码优化时发现有很多可以优化的部分。比如常量传播常量、合并就可以在生成 LLVM 以及生成 MIPS 指令过程中完成一部分，还有简单的基本块合并等等。

除了上述小的调整以外，最大的改动是寄存器分配的影响。在设计初期采用的是一个指令一个寄存器，且后续不会释放，代码优化选择线性寄存器分配策略，由于都是在进入函数之前做的分配，所以每一条指令的转换思路大可保持不变，但在函数调用做了比较大的调整。原先的设计是将所有的参数都存入新的函数栈上，这样可以确保程序语义的正确。但是到了代码优化时，考虑到存取指令的时间消耗大，因此遵从了 MIPS 规范，前三个寄存器用`$a1`、`$a2`、`$a3`，其余放入栈上。因此函数调用指令需要根据目标函数的参数来判断使用哪个寄存器还是栈上空间。函数调用的第二个改动是现场的恢复。原先的思路是保存当前函数体内用到的寄存器，不过从一般的角度来看，大函数调用小函数发生的概率更高，因此，保存目标函数用到的寄存器在一定程度上会有更高的效率，遂改之。

<br>

## 七、代码优化

代码优化是编译器最后，也是投入最多的部分，这过程基本按照设计初期的思路进行拓展，所以不区分编码前后设计。

笔者编译器的优化包括中端优化和后端优化。

### 7.1 中端优化

中端优化指的就是机器无关优化，即对中间代码进行简化。

#### 7.1.1 SSA

在理论课上我们学习了 SSA 形式的中间代码可以为后续优化带来很多便利，因此笔者在中端做的第一个优化就是把从 AST 生成的 LLVM 通过 `Mem2Reg` 转化成 SSA 形式。

实现 `Mem2Reg` 需要有每个定义点所在块的支配集，支配边界的信息。因此准备工作包括：生成流程控制图(CFG)，生成（严格）支配集，生成支配树，生成支配边界集合。

生成流程控制图：由于每个基本块的最后一条指令都是跳转指令(`br`、`ret`)，因此根据基本块的最后一条指令就可以生成 CFG，但是实际上由 AST 生成 LLVM 可能会在基本块的最后产生很多跳转指令，比如下面的例子。因此 AST 转 LLVM 时可以对当前的基本块的最后一条指令做特判，如果已经是一条跳转指令，则不需要再生成任何代码。

```c
int test() {
    printf("Hello World");
    return 1;
    return 2;
}
int main() {
    test();
    return 0;
}
```

生成严格支配集：这部分由于没有教程，需要自己设计，但因为笔者没有想到很好的办法，因此选择了最朴素的做法——根据定义暴力计算。X 块的支配 Y 块，充要条件是从入口块开始到达 Y 的任何一条路径都必然经过 X。因此求取任何基本块的支配集，可以采用深度优先搜索，当遍历到当前计算的基本块时就终止这条路的搜索。上述完成一次深度优先搜索，记录经过的基本块，从总的基本块减去被记录的块就是当前计算的基本块的支配集了。

生成支配树：根据支配集可以很方便地得到支配树。算法的大致思路就是：对所有基本块进行遍历处理，记为 X，遍历其支配的基本块 Y，如果 Y 的支配子树已经生成，则把其加入到 X 的子节点，并且把 Y 的支配集从 X 的支配集中剔除；如果 Y 的支配子树尚未生成，则递归处理基本块 Y。

生成支配边界：这部分完全按照教程给出的伪代码写就可以了。

`Mem2Reg`优化的思路是：遍历每个基本块中的每个指令，找到定义点（`alloca`指令以及对应的`store`指令），这些定义点的基本块的所有的支配边界都插入空 `phi`指令。完成上述操作后，在支配树上做深度优先遍历，删除`alloca`指令，并为其建立堆栈，对于`store`指令，将存入的值push到栈顶，并删除，对于`load`指令，取出栈顶元素进行替换。然后查看当前基本块的后继块(CFG)，对所有 `phi`指令，从对应的栈顶取出值填入。



#### 7.1.2 死代码删除

`Mem2Reg`优化过程中删去了大部分的`alloca`、`store`和`load`指令，其实已经删去了一部分死代码，即无用的重复赋值语句。但是中间代码中还是会保留很多可能存在的死代码。

死代码可以粗暴地理解为对程序输出结果无关的代码，比如下面两个程序的结果是一致的，定义语句`int a = ...`就是死代码。

```c
int main() {
    int a = 1 + 2 + 3 + 4 + 5;
    return 0;
}

int main() {
    return 0;
}
```

判断一条指令属不属于死代码，可以依据 def-use 链，即查看该指令后续是否被使用了，如果使用则不属于死代码。当然这样判断会错过许多可以优化的机会，比如 `instr1 -> instr2 -> instr3`，指令 3 使用指令 2，指令 2 使用指令 1。如果指令 3 不被使用且对程序的输出没有任何作用，则仅会删除指令 3。然而实际上，上述指令均应识别为死代码。

因此死代码删除被调整为一个递归过程：首先确定一些对程序有用的指令：`call`、`br`、`ret`、`store`。对于每一条指令，追踪其 def-use 链，检查其user是否是上述指令的一种，如果是则保留该指令，否则进行删除。下面展示出伪代码：

```java
private static boolean deleteDeadInstr(Instr instr) {
    ... // 如果是有用指令，返回 true
    
    boolean isDead = true;
    for (Value user : instr.getUserList()) {
        isDead &= deleteDeadInstrDFS((Instr) user);
    }
    if (isDead) {
        // 删除 instr
    }
    return isDead;
}
```



#### 7.1.3 常量折叠

常量的计算可以在编译期间完成，对于计算型的程序，这可能带来很大的性能提升。

对于计算指令两个操作数都是常数，可以直接计算。计算可以迭代进行，比如`b=a+1，c=b+1`，如果b不被其他指令使用，则可以简化成`b=a+2`。

此外，还有一些简单的常量折叠也可以实现：

`a+0`->`a`，`a-0`->`a`，`a*0`->`0`, `a*a`->`a+a`，`a/a`->`1`，`a%a`->`0`。

在做常量折叠时需要注意维护指令间的 use-def 链。

常量折叠优化可以分到多个过程执行，比如 AST 中 addExp、mulExp 结点转 LLVM 时，就可以完成一部分常量折叠。在 `Mem2Reg`后，中间代码会暴露出更多可以做常量折叠的机会，包括后文提到的 `GVN` 优化也会产生常量折叠的机会。



#### 7.1.4 基本块合并

生成的 LLVM 中间代码会出现很多一个基本块中只有一条 `br` 指令，且目标块仅有次一个入口，这种情况下可以将两个基本块做合并，减少一条跳转指令。这看似不会有多少性能提升，但对于循环指令，优化收益还是可观的。

合并基本块同样需要追踪 def-use 链，合并时需要更改对应`br`指令的操作数，保证合并后的 use-def 链正确。



#### 7.1.5 GVN 优化

`GVN` 优化个人认为就是提取公共子表达式，通过复用之前可达的前述指令，从而减少指令数量，实现优化。因为中间代码被转化成 SSA 形式，所以提取公共子表达式变得简单许多。

本人实现的 `GVN` 策略是：在支配树上做深度优先遍历，对于经过的每一个指令，用代表性的字符串进行标记，若后续指令的操作数`operand`的代表性字符串已经出现，则可以使用前面的指令进行替换。需要注意的是，遍历过程的回溯是需要恢复现场的，保证标记的指令都是可达的。比如下图block1 可以跳转到 block2 和 block3，因此 block1 的指令对于 2、3 都是可见的，但block2、block3不是父子结点关系，指令不互相可见，因此标记指令是严格依赖于支配树的关系。

```
block1
  |
  |——block2
  |——blcok3
```

"用代表性的字符串进行标记" 中的代表性字符串是不包含指令的寄存器信息的。比如`%local_2 = icmp ne i32 %local_1, 0`的代表性

字符串就是 `icmp ne i32 %local_1, 0`。

当然也不是所有指令都可以当作公共子表达式，比如 `load`指令就不能被当作公共子表达式，举例说明：

```
store i32 1, i32* @global_0
%local_1 = load i32, i32* @global_0
call void @putint(i32 %local_1)
store i32 -1, i32* @global_0
%local_2 = load i32, i32* @global_0
call void @putint(i32 %local_2)
```

显然`%local_2`不能被替换成`%local_1`。



### 7.2 后端优化

后端优化指生成汇编指令过程中或生成后进行的代码优化。

#### 7.2.1 消除 phi

中端优化通过插入 `phi` 指令，得到 SSA 形式的 LLVM，但因为 `phi` 指令无法直接翻译成 mips，因此需要先消除 `phi`指令。按照实验教程给的思路是：找到 `phi`指令使用的基本块，在基本块的尾部插入 `move` 指令。但是对于有多个后继块的前驱块来说，直接插入 `move` 指令会导致程序语义错误，所以需要一个中间的基本块承接这些`move`指令。这部分并不困难，按照教程就可以完成。

消除`phi`会产生很多的 `move`指令，一方面原因是因为是`phi`可能关联多个基本块，每个基本块需要产生一条`move`指令，另一方面是多个`phi`指令是并行的，而一对一地生成`move`指令是会导致错误，因此需要引入临时寄存器来存储，比如下面的例子：

```
move $1 $2
move $3 $1
```

需要再引入一条新的`move`指令：

```
move $1_temp $1
move $1 $2
move $3 $1_temp
```

实际上，可以把每一条`move`指令当作是一个图上的结点，如果指令 x 使用的寄存器是指令 y 存入的寄存器，则说指令 x 是 指令 y 的前驱。如此可形成一张有向图，依靠拓扑排序重新排序`move`指令，比如上面的例子就可以重新排序得到：

```
move $3 $1
move $1 $2
```

当然，拓扑排序要求无环图，因此需要先检查是否有环，如果有，则必须引入新的`move`指令，破除环路。

笔者在消除 `phi`指令时虽然是放在生成 mips 前做的，但还是直接在中间代码层面进行消除。需要自定义新的指令`pcopy`仿照`move`指令，`palloca`定义额外`move`指令的中间变量，同时考虑到生成 mips 时需要先分配寄存器后使用，所以把 `phi`转移到其支配树的父节点上，保留下来，当作定义点，而实际不会生成任何汇编代码，仅用于分配寄存器。



#### 7.2.2 寄存器分配

实验教程推荐使用的是图着色算法，但是流程比较复杂，因此我选择**线性寄存器分配**的算法，即计算每一条指令的活跃区间。当指令活跃时分配保留其寄存器，不活跃时释放寄存器，最终的效果还比较突出。

计算指令活跃区间的方法运用了实验课的数据流分析法，采用逆序的顺序依次计算每个指令的活跃信息。

```
in[s] = use[s] ∪ (out[s]-def[s])
out[B] = ∪in[P]
```

`in[s]`是指令 s 入口的活跃变量集合，`out[s]`是指令 s 出口的活跃变量集合，`use[s]`是指令使用的变量集，`def[s]`为指令 s 本身。

P 是 B 的后继块，所有基本块的出口活跃变量集是其所有后继块入口活跃变量的并集。

计算出每一个指令的活跃区间后，就可以在生成 MIPS 前先为每一个指令分配好寄存器或栈上空间，建立映射关系。之后携带这部分映射信息进行 MIPS 生成。



#### 7.2.3 指令选择

指令选择对最终的汇编程序效率影响很大。因为 LLVM 翻译成 mips，几乎是一对一地翻译，所以指令选择的好坏从整个程序来看会带来很大的影响。

对于乘除法，可以用加法或位运算尽可能进行替换。

对于`gep`中间代码的翻译，需要计算数组的地址信息，因此有大量的计算操作，减少一条指令最终带来的收益都是可观的。如果是常量计算则直接在编译期间完成。在转成成地址时，需要乘上类型的字节大小，又因为所有类型的字节都是2的幂次，因此可以用移位指令(`sll`)替代。

对于 `call` 指令，会产生非常多的存取内存指令。笔者采用的策略是，首先需要将目标函数所用的寄存器存入到栈上，然后将参数传给`$ai`寄存器，其中前三个寄存器存放到`$a1`、`$a2`、`$a3`(`$a0`寄存器仅用于系统调用)，多余的参数则推入栈中，符合 MIPS 标准。在转函数调用指令时，本人遇到了一个容易被忽视的错误，就是函数的参数是所在函数的形参。比如下面的情况，如果直接将参数存入到指定的位置，就会变成`move $a1$ a2`、`move $a2 $a1`，这样参数传递就是错误的。一种可行粗暴的方法就是所有传参都从栈上取，因为寄存器已经被`sw`到栈上，所以取栈上数据可以保证正确，另外高效的方法是采用类似`phi`指令的并行化处理的思路，使用拓扑排序调整指令顺序，必要时引入中间变量(临时寄存器)破除环路。

```c
void test(a, b) {
    test(b, a);
}
```

其余的指令翻译可以一一对应，需要注意的是跳转指令`br`以及`zext`指令，其操作数必然有`icmp`指令，而`icmp`指令不便对应到 MIPS 中，因此所有的`icmp`都需要和`br`或`zext`联合，利用`slt`、`sltu`、`beq`、`bne`、`xor`等指令进行组合来翻译。



#### 7.2.4 乘除法优化

乘除法优化我主要针对操作数是 2 的幂次的情况进行优化。

对于乘法，可以用移位指令 `sll` 代替。

对于除法或取模运算，可以用`sra`、`andi`指令代替。比如`a/64`，64的幂次是 6，因此可以代替成`a >> 5`。

教程中给出了除法优化更一般的算法，但是受限于时间紧迫，这部分只能暂时放弃。



