# 设计文档



## 一、参考编译器介绍

实验主要参考了 Hyggge 学长的编译器：[Petrichor](https://github.com/Hyggge/Petrichor)、和毕昇杯“喵喵队仰卧起坐”队编译器：[compiler2022-meowcompiler](https://gitlab.eduxiji.net/educg-group-12619-928705/compiler2022-meowcompiler)。

文件结构的设计主要学习了 Hyggge 学长，分成了前中后端。不一样的是我把中间代码的先关类和优化都归与中端，前端主要负责词法分析，语法分析和错误处理。

在生成中间代码 LLVM 时，由于笔者愚钝，并不了解 "万物皆`Value`" 这一思想的核心，也不清楚分成 `User`设计的原因。看完 Hyggge 学长的编译器设计恍然大悟，不由发觉 LLVM 设计的精妙之处，后续编写代码是更是享受了这种结构带来的极大便利。

compiler2022-meowcompiler 在文件分类上更加详细，包括前中后端、中间代码、错误处理等都分成多个包。因鉴于理论课上学习到编译器结构，故没有作这种详细的区分。但是在优化上，毕昇杯“喵喵队仰卧起坐”队编译器做了非常多的优化，令人叹服，给我的优化带来很多启发。

<br>

## 二、编译器总体设计

### 2.1 文件组织

文件组织如下：

```
├─docs                          # 文档
├─src
│  ├─backend                    # 后端代码
│  │  └─mips                    # 生成 mips 相关代码
│  │
│  ├─frontend                   # 前端代码
│  │  ├─lexer                   # 词法分析器
│  │  ├─semantics               # 语义分析器
│  │  │  └─symbol               # 符号表
│  │  └─syntax                  # 语法分析器
│  │      └─ast                 # 语法树
│  │
│  ├─midend                     # 中端代码
│  │  ├─llvmir                  # llvm-ir 定义
│  │  │  ├─type
│  │  │  └─value
│  │  └─optimize                # 中端优化类
│  │
│  └─util                       # 工具类
└─test                          # 测试样例集
```



### 2.2 总体结构

笔者的编译器采用Java语言编写，实现从 C 语言子集到 MIPS 的编译。在结构上，按功能和特点分为前端，中端，后端三部分：

- 前端：主要包括和输入源文件（C代码）有关的分析处理，有词法分析、语法分析、语义分析，错误处理。
- 中端：包括中间代码的相关部分，有 LLVM IR 的定义，以及常见的中间代码优化。
- 后端：包括和目标指令（MIPS）有关的代码，如 MIPS 指令类的定义，`MipsBuilder` 单例辅助生成 MIPS等等。



### 2.3 接口设计

#### 2.3.1 前端



#### 2.3.2 中端



#### 2.3.3 后端



<br>

## 三、词法分析设计

### 3.1 编码前设计

词法分析部分通过对输入的程序源码字符串进行从左往右的解析，分析出有独立词法含义的符号进行存储，并识别出其类别以供语法分析器进行使用。

词法分析的规则见下图：

<img src=".\images\lexer-1.png" style="zoom: 67%;" />

为了提高编译器的执行效率，设计时我选择使用语法分析和词法分析统一的方式，即词法分析和语法分析都在同一遍中实现。

词法分析部分主要涉及的类有`Lexer`和`LexType`。

`LexType`枚举类，存放每种单词的类别，对应上表规则中的类别码，便于后续的语法分析使用。其内部的逻辑功能比较简单，只需实现根据对应单词 `token` 解析类别码的功能即可。

```java
public static LexType parse(String token) {
    switch (token) {
        case "main":
            return MAINTK;
        //...
    }
}
```

在 `LexType`中实现`parse`函数的原因是为词法分析器提供接口，完成两个类的解耦，简化代码的同时，也避免因为在 `Lexer` 中写错单词带来的隐蔽 bug，方便调试。

`Lexer`词法分析器，存放词法分析每次得到的结果，包括`token`、`lexType` 等，内部封装了词法分析的主要逻辑。

```java
public class Lexer {
    private final String source;        // input program
    private String token;               // value of word
    private LexType lexType;            // type of word
    private int lineNumber;             // number of line
    private int curPos;                 // index
    //...
}
```

`Lexer`词法分析的核心逻辑放在`next`函数中，该函数读取下一个单词，并更新到对应属性上，提供接口是的语法分析器可以进行查看。

`next`读取单词的逻辑根据单词类别有所区别：

- 分界符：`!`、`&&`、`||`、`+`、`-`、`*`、`/`、`%`、`<`、`<=`、`>=`、`==`、`>`、`!=`、`=`、`;`、`,`、`(`、`)`、`[`、`]`、`{`、`}`。这类单词的识别直接特殊处理，根据自动机判断即可。但对于双分界符需要多判断下一个字符。比如`>=`，读取到`>`是需要再判断下一个字符是不是`=`，是则识别出`>=`，否则识别出`>`。

- 无符号整数：识别时如果发现**刚开始**读到的字符是一个数字，则循环读取数字拼接。（标识符中要求以字母开头，因此不会和无符号整数的识别相矛盾）

- 注释：分成单行注释和多行注释，需要与除号的识别合并处理，是词法分析的难点。下面给出实现的总体思路（省去了繁琐的实现细节）。

  ```java
  if (source.charAt(curPos) == '/') {
      token = "/";
      if (curPos + 1 < source.length() && source.charAt(curPos + 1) == '/') {
          // 不断读取下个字符直至遇到换行符或结尾
          return next(); 
      } else if (curPos + 1 < source.length() && source.charAt(curPos + 1) == '*') {
          curPos += 2;
          while (curPos < source.length()) {
              // 不断读取字符知道遇到 *
              // 不断读取 *
              // 判断：如果是 /,在此调用 next()，否则继续循环
          }
      }
      lexType = LexType.parse(token);
  }
  ```

- 标识符：程序中的变量。如果不是上述的字符类型，直接不断读取下一个字符直至到空白字符。

- 保留字：`mian`、`const`、`int`、`break`、`continue`、`if`、`else`、`for`、`getint`、`printf`、`return`、`void`。保留字的识别和标识符的识别可以放在一起进行，通过`LexType`的`parse`方法可以判断是保留字还是标识符，从而简化代码。

  

### 3.2 编码后修改

在实现语法分析过程中，发现不可避免地需要使用**预读**操作，因为先前设计的词法分析器中没有实现这个功能，所以添加了`foresee`方法用于返回预读的结果。因为语法分析通过预读操作判定下一步解析动作只涉及了单词类别码，因此返回值是`ArrayList<LexType>`。

在`foresee`函数逻辑中，保存当前的环境(`token`、`lexType`、`lineNumber`、`curPos`)，然后调用已经实现好的`next`函数得到预读结果，在返回时恢复保存的环境。

```java
public ArrayList<LexType> foresee(int times) {
    // 保存现场
    ArrayList<LexType> res = new ArrayList<>();
    for (int i = 0; i < times; ++i) {
        this.next();
        res.add(this.lexType);
    }
    // 恢复现场
    return res;
}
```

<br>

## 四、语法分析设计

### 4.1 编码前设计

语法分析阶段需要利用词法分析器提取单词，根据文法规则自顶向下，通过递归下降分析法，构建出一棵语法树。

语法分析部分需要完成的类有`Parser`、`SyntaxType`、以及各种结点类。在设计阶段，为了可以将程序转化成严谨完整的语法树，我为每一个语法结构都创建了一个类，这些类都继承于`Node`结点类。比如下面的语法规则，就需要为`Block`、`Decl`、`Stmt`分别建类。（语法分析不需要输出"BlockItem"，在文法中是一个多余的非终结符，因此没有建类）

<img src="images\parser-1.png" style="zoom:70%;" />

`SyntaxType`枚举类，作用和`LexType`几乎一样，标识每一个语法树结点的类别。这部分逻辑和`LexType`很像，但因为文法规则每个非终结符我都建立了类，为了做区别，`SyntaxType`需要增加更多的语法类别作区分。之所以把这两个类分开写，是因为词法分析的词法类别和文法分析的语法类别我认为是两个部分的内容，应该有所区分，虽然代码和逻辑是重复的，但我认为这么做可以使代码结构和类的功能有清晰的划分。

语法树的结点类，这部分所有类都继承自公共基类`Node`。在语法分析部分，这些类的功能几乎都是一致的，只需要存储子节点即可，因此这些公共逻辑都写在了`Node`中。

```java
public class Node {
    protected SyntaxType type;              // type of syntax
    protected ArrayList<Node> children;     // children nodes
}
```

虽然在语法分析阶段，为每一个语法成分都写一个类劳心伤神，但这是必要的，因为每个类的语法逻辑是有区别的，在后续生成中间代码可以在每个子类中单独写，避免做过多的特判，也避免用一个类表示所有节点导致类的体积过于臃肿。

`Parser`语法分析器，封装了语法分析的所有逻辑，采用递归下降分析方法，为每一个语法结构也就是文法中的非终结符，都实现一个`parseXXX`方法，返回该非终结符对应的对象。一旦要识别要匹配某一非终结符时，则调用其方法即可。

通过分析文法规则，需要处理两类问题，分别是**多产生式**和**左递归问题**。

多产生式在该编译实验中以下面两条文法规则为代表：

<img src="images\parser-2.png" style="zoom:67%;" />

<img src="images\parser-3.png" style="zoom:67%;" />

对于第一条文法，我采用预读单词的办法，在词法分析器`Lexer`中实现预读的接口。对于第一条文法而言，发现无论什么情况下总能通过预读三个单词就可以判断调用那个非终结符的`parse`方法。

而对于第二条文法中有`Stmt-> Lval = Exp; | [Exp]; | LVal = getint();`这三个产生式是本次实验的难点。和上一条文法不同，`Exp` 可以经过若干有限次推导得到 `Lval`，同时也无法预判 `Lval` 的长度，因此预读的方法不可行。所以我采用对于这三种产生式的情况都用 `Exp` 的解析方法去解析，如果解析后下一个字符是 `;` ，那么刚才的解析方法就是正确的，如果下一个字符是 `=`，那么就可以说明前面的符号应该是 `Lval`，在从`Exp` 的树中截取 `Lval` 的子树当作上次解析的结果。

第二个难点问题是左递归问题。因为编译器解析程序的顺序是从左往右进行的，如果遇到做递归文法不作修改，那么`parseXXX`方法会进入无穷的调用，从而出错。因此左递归文法需要经过变形可以变成正则表达式，但是如果变化后，原先的语法树也会跟着变形。为了保证语法树不变，每次读到分界符时，对之前解析得到的树结点重新进行生成，保证语法树不变。

以文法 `AddExp → MulExp | AddExp ('+' | '−') MulExp`为例进行说明：

```java
private AddExp parseAddExp() {
    MulExp mulExp = parseMulExp()
    AddExp addExp = new AddExp(mulExp);
    while (true) {
        if (读到了 + 或 -) {
        	addExp = new AddExp(addExp, parseMulExp());
        }
    }
    return addExp;
}
```

解决完上述问题，语法分析器就大抵都可以实现了。



### 4.2 编码后修改

在错误处理部分，发现语法分析预留的错误处理接口不太适用。因为笔者设计的错误分析是重新的一遍，在抽象语法树上进行的，因此语义错误，语法错误等信息都必须携带导语法树上。这要求语法分析需要能够容忍一定的语法错误，如右括号缺省，分号缺失等等。而在之前语法分析过程中，往往需要这些终结符号作为分界辅助分析。如今要能够处理这些缺失的情况，需要对语法分析的逻辑做些调整。往往还要根据文法计算 FIRST 集 FOLLOW 集等。

<br>

## 五、错误处理设计

### 5.1 编码前设计

编译器的错误处理是比较复杂的，因为并不知道输入的源程序串会出现怎么样的错误，这会导致词法分析乃至语法分析都难以实现。因此本实验的错误处理是限定在一约束要求内的，需要考虑的错误如下表所示。

![](images\error-1.png)

这些错误大抵可以分成三类：

- 词法分析错误：a
- 语法分析错误：i，j，k
- 语义分析错误：b，c，d，e，f，g，h，l，m

在设计错误处理时，为了避免语法分析器代码量过于庞大，导致后续难以维护，添加了新的语义分析类`SemanticAnalyzer`，在语义分析中完成错误分析和中间代码生成，当然这样需要对语法分析得到的语法树进行操作，相当于扫描了程序两遍，即便会有效率的损失，但为了便于代码的可拓展性和可维护性来说是值得的。

在语义分析器类中，调用语法树最顶层的节点的方法





### 5.2 编码后修改



## 六、代码生成设计



## 七、代码优化

代码优化是编译器最后，也是投入最多的部分，这过程基本按照设计初期的思路进行拓展，所以不区分编码前后设计。

笔者编译器的优化包括中端优化和后端优化。

### 7.1 中端优化

中端优化指的就是机器无关优化，即对中间代码进行简化。

#### 7.1.1 SSA

在理论课上我们学习了 SSA 形式的中间代码可以为后续优化带来很多便利，因此笔者在中端做的第一个优化就是把从 AST 生成的 LLVM 通过 `Mem2Reg` 转化成 SSA 形式。

实现 `Mem2Reg` 需要有每个定义点所在块的支配集，支配边界的信息。因此准备工作包括：生成流程控制图(CFG)，生成（严格）支配集，生成支配树，生成支配边界集合。

生成流程控制图：由于每个基本块的最后一条指令都是跳转指令(`br`、`ret`)，因此根据基本块的最后一条指令就可以生成 CFG，但是实际上由 AST 生成 LLVM 可能会在基本块的最后产生很多跳转指令，比如下面的例子。因此 AST 转 LLVM 时可以对当前的基本块的最后一条指令做特判，如果已经是一条跳转指令，则不需要再生成任何代码。

```c
int test() {
    printf("Hello World");
    return 1;
    return 2;
}
int main() {
    test();
    return 0;
}
```

生成严格支配集：这部分由于没有教程，需要自己设计，但因为笔者没有想到很好的办法，因此选择了最朴素的做法——根据定义暴力计算。X 块的支配 Y 块，充要条件是从入口块开始到达 Y 的任何一条路径都必然经过 X。因此求取任何基本块的支配集，可以采用深度优先搜索，当遍历到当前计算的基本块时就终止这条路的搜索。上述完成一次深度优先搜索，记录经过的基本块，从总的基本块减去被记录的块就是当前计算的基本块的支配集了。

生成支配树：根据支配集可以很方便地得到支配树。算法的大致思路就是：对所有基本块进行遍历处理，记为 X，遍历其支配的基本块 Y，如果 Y 的支配子树已经生成，则把其加入到 X 的子节点，并且把 Y 的支配集从 X 的支配集中剔除；如果 Y 的支配子树尚未生成，则递归处理基本块 Y。

生成支配边界：这部分完全按照教程给出的伪代码写就可以了。

`Mem2Reg`优化的思路是：遍历每个基本块中的每个指令，找到定义点（`alloca`指令以及对应的`store`指令），这些定义点的基本块的所有的支配边界都插入空 `phi`指令。完成上述操作后，在支配树上做深度优先遍历，删除`alloca`指令，并为其建立堆栈，对于`store`指令，将存入的值push到栈顶，并删除，对于`load`指令，取出栈顶元素进行替换。然后查看当前基本块的后继块(CFG)，对所有 `phi`指令，从对应的栈顶取出值填入。



#### 7.1.2 死代码删除

`Mem2Reg`优化过程中删去了大部分的`alloca`、`store`和`load`指令，其实已经删去了一部分死代码，即无用的重复赋值语句。但是中间代码中还是会保留很多可能存在的死代码。

死代码可以粗暴地理解为对程序输出结果无关的代码，比如下面两个程序的结果是一致的，定义语句`int a = ...`就是死代码。

```c
int main() {
    int a = 1 + 2 + 3 + 4 + 5;
    return 0;
}

int main() {
    return 0;
}
```

判断一条指令属不属于死代码，可以依据 def-use 链，即查看该指令后续是否被使用了，如果使用则不属于死代码。当然这样判断会错过许多可以优化的机会，比如 `instr1 -> instr2 -> instr3`，指令 3 使用指令 2，指令 2 使用指令 1。如果指令 3 不被使用且对程序的输出没有任何作用，则仅会删除指令 3。然而实际上，上述指令均应识别为死代码。

因此死代码删除被调整为一个递归过程：首先确定一些对程序有用的指令：`call`、`br`、`ret`、`store`。对于每一条指令，追踪其 def-use 链，检查其user是否是上述指令的一种，如果是则保留该指令，否则进行删除。下面展示出伪代码：

```java
private static boolean deleteDeadInstr(Instr instr) {
    ... // 如果是有用指令，返回 true
    
    boolean isDead = true;
    for (Value user : instr.getUserList()) {
        isDead &= deleteDeadInstrDFS((Instr) user);
    }
    if (isDead) {
        // 删除 instr
    }
    return isDead;
}
```



#### 7.1.3 常量折叠

常量的计算可以在编译期间完成，对于计算型的程序，这可能带来很大的性能提升。

对于计算指令两个操作数都是常数，可以直接计算。计算可以迭代进行，比如`b=a+1，c=b+1`，如果b不被其他指令使用，则可以简化成`b=a+2`。

此外，还有一些简单的常量折叠也可以实现：

`a+0`->`a`，`a-0`->`a`，`a*0`->`0`, `a*a`->`a+a`，`a/a`->`1`，`a%a`->`0`。

在做常量折叠时需要注意维护指令间的 use-def 链。

常量折叠优化可以分到多个过程执行，比如 AST 中 addExp、mulExp 结点转 LLVM 时，就可以完成一部分常量折叠。在 `Mem2Reg`后，中间代码会暴露出更多可以做常量折叠的机会，包括后文提到的 `GVN` 优化也会产生常量折叠的机会。



#### 7.1.4 基本块合并

生成的 LLVM 中间代码会出现很多一个基本块中只有一条 `br` 指令，且目标块仅有次一个入口，这种情况下可以将两个基本块做合并，减少一条跳转指令。这看似不会有多少性能提升，但对于循环指令，优化收益还是可观的。

合并基本块同样需要追踪 def-use 链，合并时需要更改对应`br`指令的操作数，保证合并后的 use-def 链正确。



#### 7.1.5 GVN 优化

`GVN` 优化个人认为就是提取公共子表达式，通过复用之前可达的前述指令，从而减少指令数量，实现优化。因为中间代码被转化成 SSA 形式，所以提取公共子表达式变得简单许多。

本人实现的 `GVN` 策略是：在支配树上做深度优先遍历，对于经过的每一个指令，用代表性的字符串进行标记，若后续指令的操作数`operand`的代表性字符串已经出现，则可以使用前面的指令进行替换。需要注意的是，遍历过程的回溯是需要恢复现场的，保证标记的指令都是可达的。比如下图block1 可以跳转到 block2 和 block3，因此 block1 的指令对于 2、3 都是可见的，但block2、block3不是父子结点关系，指令不互相可见，因此标记指令是严格依赖于支配树的关系。

```
block1
  |
  |——block2
  |——blcok3
```

"用代表性的字符串进行标记" 中的代表性字符串是不包含指令的寄存器信息的。比如`%local_2 = icmp ne i32 %local_1, 0`的代表性

字符串就是 `icmp ne i32 %local_1, 0`。

当然也不是所有指令都可以当作公共子表达式，比如 `load`指令就不能被当作公共子表达式，举例说明：

```
store i32 1, i32* @global_0
%local_1 = load i32, i32* @global_0
call void @putint(i32 %local_1)
store i32 -1, i32* @global_0
%local_2 = load i32, i32* @global_0
call void @putint(i32 %local_2)
```

显然`%local_2`不能被替换成`%local_1`。



### 7.2 后端优化

后端优化指生成汇编指令过程中或生成后进行的代码优化。

#### 7.2.1 消除 phi

中端优化通过插入 `phi` 指令，得到 SSA 形式的 LLVM，但因为 `phi` 指令无法直接翻译成 mips，因此需要先消除 `phi`指令。按照实验教程给的思路是：找到 `phi`指令使用的基本块，在基本块的尾部插入 `move` 指令。但是对于有多个后继块的前驱块来说，直接插入 `move` 指令会导致程序语义错误，所以需要一个中间的基本块承接这些`move`指令。这部分并不困难，按照教程就可以完成。

消除`phi`会产生很多的 `move`指令，一方面原因是因为是`phi`可能关联多个基本块，每个基本块需要产生一条`move`指令，另一方面是多个`phi`指令是并行的，而一对一地生成`move`指令是会导致错误，因此需要引入临时寄存器来存储，比如下面的例子：

```
move $1 $2
move $3 $1
```

需要再引入一条新的`move`指令：

```
move $1_temp $1
move $1 $2
move $3 $1_temp
```

实际上，可以把每一条`move`指令当作是一个图上的结点，如果指令 x 使用的寄存器是指令 y 存入的寄存器，则说指令 x 是 指令 y 的前驱。如此可形成一张有向图，依靠拓扑排序重新排序`move`指令，比如上面的例子就可以重新排序得到：

```
move $3 $1
move $1 $2
```

当然，拓扑排序要求无环图，因此需要先检查是否有环，如果有，则必须引入新的`move`指令，破除环路。

笔者在消除 `phi`指令时虽然是放在生成 mips 前做的，但还是直接在中间代码层面进行消除。需要自定义新的指令`pcopy`仿照`move`指令，`palloca`定义额外`move`指令的中间变量，同时考虑到生成 mips 时需要先分配寄存器后使用，所以把 `phi`转移到其支配树的父节点上，保留下来，当作定义点，而实际不会生成任何汇编代码，仅用于分配寄存器。



#### 7.2.2 寄存器分配

实验教程推荐使用的是图着色算法，但是流程比较复杂，因此我选择**线性寄存器分配**的算法，即计算每一条指令的活跃区间。当指令活跃时分配保留其寄存器，不活跃时释放寄存器，最终的效果还比较突出。

计算指令活跃区间的方法运用了实验课的数据流分析法，采用逆序的顺序依次计算每个指令的活跃信息。

```
in[s] = use[s] ∪ (out[s]-def[s])
out[B] = ∪in[P]
```

`in[s]`是指令 s 入口的活跃变量集合，`out[s]`是指令 s 出口的活跃变量集合，`use[s]`是指令使用的变量集，`def[s]`为指令 s 本身。

P 是 B 的后继块，所有基本块的出口活跃变量集是其所有后继块入口活跃变量的并集。

计算出每一个指令的活跃区间后，就可以在生成 MIPS 前先为每一个指令分配好寄存器或栈上空间，建立映射关系。之后携带这部分映射信息进行 MIPS 生成。



#### 7.2.3 指令选择

指令选择对最终的汇编程序效率影响很大。因为 LLVM 翻译成 mips，几乎是一对一地翻译，所以指令选择的好坏从整个程序来看会带来很大的影响。

对于乘除法，可以用加法或位运算尽可能进行替换。

对于`gep`中间代码的翻译，需要计算数组的地址信息，因此有大量的计算操作，减少一条指令最终带来的收益都是可观的。如果是常量计算则直接在编译期间完成。在转成成地址时，需要乘上类型的字节大小，又因为所有类型的字节都是2的幂次，因此可以用移位指令(`sll`)替代。

对于 `call` 指令，会产生非常多的存取内存指令。笔者采用的策略是，首先需要将目标函数所用的寄存器存入到栈上，然后将参数传给`$ai`寄存器，其中前三个寄存器存放到`$a1`、`$a2`、`$a3`(`$a0`寄存器仅用于系统调用)，多余的参数则推入栈中，符合 MIPS 标准。在转函数调用指令时，本人遇到了一个容易被忽视的错误，就是函数的参数是所在函数的形参。比如下面的情况，如果直接将参数存入到指定的位置，就会变成`move $a1$ a2`、`move $a2 $a1`，这样参数传递就是错误的。一种可行粗暴的方法就是所有传参都从栈上取，因为寄存器已经被`sw`到栈上，所以取栈上数据可以保证正确，另外高效的方法是采用类似`phi`指令的并行化处理的思路，使用拓扑排序调整指令顺序，必要时引入中间变量(临时寄存器)破除环路。

```c
void test(a, b) {
    test(b, a);
}
```

其余的指令翻译可以一一对应，需要注意的是跳转指令`br`以及`zext`指令，其操作数必然有`icmp`指令，而`icmp`指令不便对应到 MIPS 中，因此所有的`icmp`都需要和`br`或`zext`联合，利用`slt`、`sltu`、`beq`、`bne`、`xor`等指令进行组合来翻译。



#### 7.2.4 乘除法优化

乘除法优化我主要针对操作数是 2 的幂次的情况进行优化。

对于乘法，可以用移位指令 `sll` 代替。

对于除法或取模运算，可以用`sra`、`andi`指令代替。比如`a/64`，64的幂次是 6，因此可以代替成`a >> 5`。

教程中给出了除法优化更一般的算法，但是受限于时间紧迫，这部分只能暂时放弃。



