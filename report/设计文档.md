# 设计文档



## 一、参考编译器介绍

<br>

## 二、编译器总体设计

<br>

## 三、词法分析设计

### 3.1 编码前设计

词法分析部分通过对输入的程序源码字符串进行从左往右的解析，分析出有独立词法含义的符号进行存储，并识别出其类别以供语法分析器进行使用。

词法分析的规则见下图：

<img src=".\images\lexer-1.png" style="zoom: 67%;" />

为了提高编译器的执行效率，设计时我选择使用语法分析和词法分析统一的方式，即词法分析和语法分析都在同一遍中实现。

词法分析部分主要涉及的类有`Lexer`和`LexType`。

`LexType`枚举类，存放每种单词的类别，对应上表规则中的类别码，便于后续的语法分析使用。其内部的逻辑功能比较简单，只需实现根据对应单词 `token` 解析类别码的功能即可。

```java
public static LexType parse(String token) {
    switch (token) {
        case "main":
            return MAINTK;
        //...
    }
}
```

在 `LexType`中实现`parse`函数的原因是为词法分析器提供接口，完成两个类的解耦，简化代码的同时，也避免因为在 `Lexer` 中写错单词带来的隐蔽 bug，方便调试。

`Lexer`词法分析器，存放词法分析每次得到的结果，包括`token`、`lexType` 等，内部封装了词法分析的主要逻辑。

```java
public class Lexer {
    private final String source;        // input program
    private String token;               // value of word
    private LexType lexType;            // type of word
    private int lineNumber;             // number of line
    private int curPos;                 // index
    //...
}
```

`Lexer`词法分析的核心逻辑放在`next`函数中，该函数读取下一个单词，并更新到对应属性上，提供接口是的语法分析器可以进行查看。

`next`读取单词的逻辑根据单词类别有所区别：

- 分界符：`!`、`&&`、`||`、`+`、`-`、`*`、`/`、`%`、`<`、`<=`、`>=`、`==`、`>`、`!=`、`=`、`;`、`,`、`(`、`)`、`[`、`]`、`{`、`}`。这类单词的识别直接特殊处理，根据自动机判断即可。但对于双分界符需要多判断下一个字符。比如`>=`，读取到`>`是需要再判断下一个字符是不是`=`，是则识别出`>=`，否则识别出`>`。

- 无符号整数：识别时如果发现**刚开始**读到的字符是一个数字，则循环读取数字拼接。（标识符中要求以字母开头，因此不会和无符号整数的识别相矛盾）

- 注释：分成单行注释和多行注释，需要与除号的识别合并处理，是词法分析的难点。下面给出实现的总体思路（省去了繁琐的实现细节）。

  ```java
  if (source.charAt(curPos) == '/') {
      token = "/";
      if (curPos + 1 < source.length() && source.charAt(curPos + 1) == '/') {
          // 不断读取下个字符直至遇到换行符或结尾
          return next(); 
      } else if (curPos + 1 < source.length() && source.charAt(curPos + 1) == '*') {
          curPos += 2;
          while (curPos < source.length()) {
              // 不断读取字符知道遇到 *
              // 不断读取 *
              // 判断：如果是 /,在此调用 next()，否则继续循环
          }
      }
      lexType = LexType.parse(token);
  }
  ```

- 标识符：程序中的变量。如果不是上述的字符类型，直接不断读取下一个字符直至到空白字符。

- 保留字：`mian`、`const`、`int`、`break`、`continue`、`if`、`else`、`for`、`getint`、`printf`、`return`、`void`。保留字的识别和标识符的识别可以放在一起进行，通过`LexType`的`parse`方法可以判断是保留字还是标识符，从而简化代码。

  

### 3.2 编码后修改

在实现语法分析过程中，发现不可避免地需要使用**预读**操作，因为先前设计的词法分析器中没有实现这个功能，所以添加了`foresee`方法用于返回预读的结果。因为语法分析通过预读操作判定下一步解析动作只涉及了单词类别码，因此返回值是`ArrayList<LexType>`。

在`foresee`函数逻辑中，保存当前的环境(`token`、`lexType`、`lineNumber`、`curPos`)，然后调用已经实现好的`next`函数得到预读结果，在返回时恢复保存的环境。

```java
public ArrayList<LexType> foresee(int times) {
    // 保存现场
    ArrayList<LexType> res = new ArrayList<>();
    for (int i = 0; i < times; ++i) {
        this.next();
        res.add(this.lexType);
    }
    // 恢复现场
    return res;
}
```

<br>

## 四、语法分析设计

### 4.1 编码前设计

语法分析阶段需要利用词法分析器提取单词，根据文法规则自顶向下，通过递归下降分析法，构建出一棵语法树。

语法分析部分需要完成的类有`Parser`、`SyntaxType`、以及各种结点类。在设计阶段，为了可以将程序转化成严谨完整的语法树，我为每一个语法结构都创建了一个类，这些类都继承于`Node`结点类。比如下面的语法规则，就需要为`Block`、`Decl`、`Stmt`分别建类。（语法分析不需要输出"BlockItem"，在文法中是一个多余的非终结符，因此没有建类）

<img src="images\parser-1.png" style="zoom:70%;" />

`SyntaxType`枚举类，作用和`LexType`几乎一样，标识每一个语法树结点的类别。这部分逻辑和`LexType`很像，但因为文法规则每个非终结符我都建立了类，为了做区别，`SyntaxType`需要增加更多的语法类别作区分。之所以把这两个类分开写，是因为词法分析的词法类别和文法分析的语法类别我认为是两个部分的内容，应该有所区分，虽然代码和逻辑是重复的，但我认为这么做可以使代码结构和类的功能有清晰的划分。

语法树的结点类，这部分所有类都继承自公共基类`Node`。在语法分析部分，这些类的功能几乎都是一致的，只需要存储子节点即可，因此这些公共逻辑都写在了`Node`中。

```java
public class Node {
    protected SyntaxType type;              // type of syntax
    protected ArrayList<Node> children;     // children nodes
}
```

虽然在语法分析阶段，为每一个语法成分都写一个类劳心伤神，但这是必要的，因为每个类的语法逻辑是有区别的，在后续生成中间代码可以在每个子类中单独写，避免做过多的特判，也避免用一个类表示所有节点导致类的体积过于臃肿。

`Parser`语法分析器，封装了语法分析的所有逻辑，采用递归下降分析方法，为每一个语法结构也就是文法中的非终结符，都实现一个`parseXXX`方法，返回该非终结符对应的对象。一旦要识别要匹配某一非终结符时，则调用其方法即可。

通过分析文法规则，需要处理两类问题，分别是**多产生式**和**左递归问题**。

多产生式在该编译实验中以下面两条文法规则为代表：

<img src="images\parser-2.png" style="zoom:67%;" />

<img src="images\parser-3.png" style="zoom:67%;" />

对于第一条文法，我采用预读单词的办法，在词法分析器`Lexer`中实现预读的接口。对于第一条文法而言，发现无论什么情况下总能通过预读三个单词就可以判断调用那个非终结符的`parse`方法。

而对于第二条文法中有`Stmt-> Lval = Exp; | [Exp]; | LVal = getint();`这三个产生式是本次实验的难点。和上一条文法不同，`Exp` 可以经过若干有限次推导得到 `Lval`，同时也无法预判 `Lval` 的长度，因此预读的方法不可行。所以我采用对于这三种产生式的情况都用 `Exp` 的解析方法去解析，如果解析后下一个字符是 `;` ，那么刚才的解析方法就是正确的，如果下一个字符是 `=`，那么就可以说明前面的符号应该是 `Lval`，在从`Exp` 的树中截取 `Lval` 的子树当作上次解析的结果。

第二个难点问题是左递归问题。因为编译器解析程序的顺序是从左往右进行的，如果遇到做递归文法不作修改，那么`parseXXX`方法会进入无穷的调用，从而出错。因此左递归文法需要经过变形可以变成正则表达式，但是如果变化后，原先的语法树也会跟着变形。为了保证语法树不变，每次读到分界符时，对之前解析得到的树结点重新进行生成，保证语法树不变。

以文法 `AddExp → MulExp | AddExp ('+' | '−') MulExp`为例进行说明：

```java
private AddExp parseAddExp() {
    MulExp mulExp = parseMulExp()
    AddExp addExp = new AddExp(mulExp);
    while (true) {
        if (读到了 + 或 -) {
        	addExp = new AddExp(addExp, parseMulExp());
        }
    }
    return addExp;
}
```

解决完上述问题，语法分析器就大抵都可以实现了。



### 4.2 编码后修改



<br>

## 五、错误处理设计

### 5.1 编码前设计

编译器的错误处理是比较复杂的，因为并不知道输入的源程序串会出现怎么样的错误，这会导致词法分析乃至语法分析都难以实现。因此本实验的错误处理是限定在一约束要求内的，需要考虑的错误如下表所示。

![](images\error-1.png)

这些错误大抵可以分成三类：

- 词法分析错误：a
- 语法分析错误：i，j，k
- 语义分析错误：b，c，d，e，f，g，h，l，m

在设计错误处理时，为了避免语法分析器代码量过于庞大，导致后续难以维护，添加了新的语义分析类`SemanticAnalyzer`，在语义分析中完成错误分析和中间代码生成，当然这样需要对语法分析得到的语法树进行操作，相当于扫描了程序两遍，即便会有效率的损失，但为了便于代码的可拓展性和可维护性来说是值得的。

在语义分析器类中，调用语法树最顶层的节点的方法





### 5.2 编码后修改

